# VisionTransformer

This repository is dedicated to replicating the Vision Transformer (ViT) as described in the original paper: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale.

## Project Objective
The primary goal of this project is to create a structured approach to replicating AI papers, starting with the Vision Transformer. This process involves:

1. Understanding the architecture: Analyzing and breaking down the ViT model architecture as presented in the paper.
2. Finding hyperparameters: Identifying the relevant hyperparameters from the paper and integrating them into the implementation.
3. Data processing: Replicating the exact input data preprocessing pipeline, including patch embeddings and tokenization, as described in the paper.
4. Model replication: Coding each part of the architecture and ensuring that the behavior matches the results found in the paper.
5. Testing and validation: Ensuring the replicated model is tested against the same benchmarks provided in the paper.


## Requirements
- Python 3.7+
- PyTorch
- NumPy
- Matplotlib
